# -*- coding: utf-8 -*-
"""
æ–‡æœ¬æå–æ¨¡å—

è´Ÿè´£ä»PMCå…¨æ–‡å’ŒPDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹
åŒ…å«æ™ºèƒ½ç« èŠ‚ç­›é€‰å’Œæ–‡æœ¬ä¼˜åŒ–åŠŸèƒ½
"""

import os
import json
import time
import requests
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
import re

from utils.logger import LoggerMixin
from utils.file_handler import FileHandler
from utils.api_manager import api_manager

logger = logging.getLogger(__name__)

class TextExtractor(LoggerMixin):
    """æ–‡æœ¬æå–å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–æ–‡æœ¬æå–å™¨
        
        Args:
            config: æå–é…ç½®
        """
        self.config = config
        self.text_limit = config.get('text_limit', 15000)
        self.section_filters = config.get('section_filters', [])
        self.exclude_sections = config.get('exclude_sections', [])
        self.key_section_ratio = config.get('key_section_ratio', {})
        
        # å»¶è¿Ÿå¯¼å…¥é‡é‡çº§åº“
        self._fitz = None
        self._pdf2image = None
        self._pytesseract = None
        self._PIL_Image = None
    
    def _import_pdf_libraries(self):
        """å»¶è¿Ÿå¯¼å…¥PDFå¤„ç†åº“"""
        if self._fitz is None:
            try:
                import fitz
                self._fitz = fitz
                self.logger.debug("âœ… æˆåŠŸå¯¼å…¥PyMuPDFåº“")
            except ImportError:
                self.logger.warning("âš ï¸ PyMuPDFåº“æœªå®‰è£…ï¼ŒPDFå¤„ç†åŠŸèƒ½å°†å—é™")
        
        if self._pdf2image is None:
            try:
                from pdf2image import convert_from_path
                self._pdf2image = convert_from_path
                self.logger.debug("âœ… æˆåŠŸå¯¼å…¥pdf2imageåº“")
            except ImportError:
                self.logger.warning("âš ï¸ pdf2imageåº“æœªå®‰è£…ï¼ŒOCRåŠŸèƒ½å°†å—é™")
        
        if self._pytesseract is None:
            try:
                import pytesseract
                self._pytesseract = pytesseract
                self.logger.debug("âœ… æˆåŠŸå¯¼å…¥pytesseractåº“")
            except ImportError:
                self.logger.warning("âš ï¸ pytesseractåº“æœªå®‰è£…ï¼ŒOCRåŠŸèƒ½å°†å—é™")
        
        if self._PIL_Image is None:
            try:
                from PIL import Image
                self._PIL_Image = Image
                self.logger.debug("âœ… æˆåŠŸå¯¼å…¥PILåº“")
            except ImportError:
                self.logger.warning("âš ï¸ PILåº“æœªå®‰è£…ï¼Œå›¾åƒå¤„ç†åŠŸèƒ½å°†å—é™")
    
    def fetch_bioc_document(self, pmid: str, format_type: str = "json", 
                           encoding: str = "unicode") -> Optional[Dict[str, Any]]:
        """
        ä»NCBI BioC APIè·å–ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®æ•°æ®
        
        Args:
            pmid: æ–‡çŒ®PMID
            format_type: è¿”å›æ ¼å¼ï¼Œ'xml' æˆ– 'json'
            encoding: ç¼–ç æ ¼å¼ï¼Œ'unicode' æˆ– 'ascii'
            
        Returns:
            BioCæ–‡æ¡£çš„JSONå¯¹è±¡ï¼Œå¤±è´¥è¿”å›None
        """
        url = f"https://www.ncbi.nlm.nih.gov/research/bionlp/RESTful/pmcoa.cgi/BioC_{format_type}/{pmid}/{encoding}"
        
        try:
            self.logger.debug(f"æ­£åœ¨è·å–PMID {pmid} çš„BioCæ•°æ®...")
            
            response = api_manager.get(
                url,
                timeout=30,
                api_name='pubmed_no_key'  # BioC APIæ²¡æœ‰keyé™åˆ¶ï¼Œä½¿ç”¨è¾ƒå®½æ¾çš„é™æµ
            )
            
            if response.status_code == 200:
                data = response.json()
                if isinstance(data, list) and len(data) > 0:
                    self.logger.debug(f"âœ… æˆåŠŸè·å–PMID {pmid} çš„BioCæ•°æ®")
                    return data[0]
                else:
                    self.logger.warning(f"âš ï¸ PMID {pmid} çš„BioCæ•°æ®æ ¼å¼å¼‚å¸¸")
                    return None
            else:
                self.logger.warning(f"âš ï¸ è·å–PMID {pmid} çš„BioCæ•°æ®å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ è·å–PMID {pmid} çš„BioCæ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    def extract_meta_info(self, bioc_document: Dict[str, Any]) -> str:
        """
        ä»BioCæ–‡æ¡£ä¸­æå–å…ƒæ•°æ®ä¿¡æ¯
        
        Args:
            bioc_document: BioCæ–‡æ¡£JSON
            
        Returns:
            æ ¼å¼åŒ–çš„å…ƒæ•°æ®å­—ç¬¦ä¸²
        """
        try:
            for passage in bioc_document["documents"][0]["passages"]:
                if passage["infons"]["section_type"] == "TITLE":
                    metadata = passage["infons"]
                    
                    # å¤„ç†å…³é”®è¯
                    keywords = metadata.get('kwd', 'N/A')
                    
                    # å¤„ç†ä½œè€…ä¿¡æ¯
                    authors = [value for key, value in metadata.items() if key.startswith('name_')]
                    formatted_authors = []
                    for author in authors:
                        parts = author.split(';')
                        surname = parts[0].split(':')[1] if ':' in parts[0] else parts[0]
                        if len(parts) > 1 and ':' in parts[1]:
                            given_names = parts[1].split(':')[1]
                            formatted_name = f"{given_names} {surname}"
                        else:
                            formatted_name = surname
                        formatted_authors.append(formatted_name)
                    
                    # è·å–å…¶ä»–å…ƒæ•°æ®å­—æ®µ
                    doi = metadata.get('article-id_doi', 'N/A')
                    pmid = metadata.get('article-id_pmid', 'N/A')
                    pmcid = metadata.get('article-id_pmc', 'N/A')
                    year = metadata.get('year', 'N/A')
                    source = metadata.get('source', 'N/A')
                    volume = metadata.get('volume', 'N/A')
                    issue = metadata.get('issue', 'N/A')
                    
                    # æ ¼å¼åŒ–å…ƒæ•°æ®æ–‡æœ¬
                    meta_text = f"""æ ‡é¢˜: {passage['text']}
DOI: {doi}
PMID: {pmid}
PMCID: PMC{pmcid}
å¹´ä»½: {year}
æœŸåˆŠ: {source}, å·å· {volume}, æœŸå· {issue}
å…³é”®è¯: {keywords}
ä½œè€…: {', '.join(formatted_authors)}"""
                    
                    return meta_text
                    
        except Exception as e:
            self.logger.warning(f"æå–å…ƒæ•°æ®ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        
        return "å…ƒæ•°æ®æå–å¤±è´¥"
    
    def extract_full_text_from_bioc(self, bioc_document: Dict[str, Any]) -> str:
        """
        ä»BioCæ–‡æ¡£ä¸­æå–å…¨æ–‡å†…å®¹
        
        Args:
            bioc_document: BioCæ–‡æ¡£JSON
            
        Returns:
            å…¨æ–‡å†…å®¹å­—ç¬¦ä¸²
        """
        try:
            # è·å–æ‰€æœ‰ç« èŠ‚ç±»å‹
            section_types = []
            for passage in bioc_document["documents"][0]["passages"]:
                section_type = passage["infons"]["section_type"]
                if (section_type not in section_types and 
                    section_type not in self.exclude_sections):
                    section_types.append(section_type)
            
            self.logger.debug(f"æå–ç« èŠ‚ç±»å‹: {section_types}")
            
            # æŒ‰ç« èŠ‚æå–æ–‡æœ¬
            full_text = ""
            section_texts = {}
            
            for section_type in section_types:
                section_text = ""
                for passage in bioc_document["documents"][0]["passages"]:
                    if passage["infons"]["section_type"] == section_type:
                        section_text += passage["text"] + "\n\n"
                
                if section_text.strip():
                    section_texts[section_type] = section_text
                    full_text += f"\n\n===== {section_type} =====\n{section_text}"
            
            return full_text.strip()
            
        except Exception as e:
            self.logger.error(f"ä»BioCæ–‡æ¡£æå–å…¨æ–‡æ—¶å‡ºé”™: {e}")
            return ""
    
    def extract_from_pdf(self, pdf_path: Union[str, Path], min_chars: int = 1000) -> str:
        """
        ä»PDFæ–‡ä»¶æå–æ–‡æœ¬
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            min_chars: æœ€å°å­—ç¬¦æ•°é˜ˆå€¼
            
        Returns:
            æå–çš„æ–‡æœ¬å†…å®¹
        """
        self._import_pdf_libraries()
        
        if self._fitz is None:
            self.logger.error("âŒ PyMuPDFåº“æœªå®‰è£…ï¼Œæ— æ³•å¤„ç†PDFæ–‡ä»¶")
            return ""
        
        pdf_path = Path(pdf_path)
        
        if not pdf_path.exists():
            self.logger.error(f"âŒ PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
            return ""
        
        try:
            self.logger.debug(f"ğŸ” å°è¯•ç›´æ¥æå–PDFæ–‡æœ¬: {pdf_path.name}")
            
            # å°è¯•ç›´æ¥æå–æ–‡æœ¬
            doc = self._fitz.open(str(pdf_path))
            text = "\n".join([page.get_text() for page in doc])
            doc.close()
            
            effective_chars = len(''.join(text.split()))
            zh_count = sum('\u4e00' <= c <= '\u9fff' for c in text)
            en_count = sum(c.isalpha() for c in text)
            
            self.logger.debug(f"æå–åˆ° {len(text)} ä¸ªå­—ç¬¦ï¼ˆæœ‰æ•ˆ: {effective_chars}, ä¸­æ–‡: {zh_count}, è‹±æ–‡: {en_count}ï¼‰")
            
            # åˆ¤æ–­æå–è´¨é‡
            if (effective_chars >= min_chars or 
                (effective_chars > 500 and (zh_count > 100 or en_count > 300))):
                self.logger.debug(f"âœ… PDFæ–‡æœ¬æå–æˆåŠŸ")
                return text
            
            # å¦‚æœæ–‡æœ¬è´¨é‡ä¸å¤Ÿï¼Œå°è¯•OCR
            self.logger.debug(f"âš ï¸ æå–æ–‡æœ¬è´¨é‡ä¸è¶³ï¼Œå°è¯•OCR...")
            return self._ocr_from_pdf(pdf_path)
            
        except Exception as e:
            self.logger.error(f"âŒ PDFæ–‡æœ¬æå–å¤±è´¥: {e}")
            return ""
    
    def _ocr_from_pdf(self, pdf_path: Path) -> str:
        """
        ä½¿ç”¨OCRä»PDFæå–æ–‡æœ¬
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            OCRè¯†åˆ«çš„æ–‡æœ¬
        """
        if (self._pdf2image is None or self._pytesseract is None or 
            self._PIL_Image is None):
            self.logger.warning("âš ï¸ OCRç›¸å…³åº“æœªå®‰è£…ï¼Œè·³è¿‡OCRå¤„ç†")
            return ""
        
        try:
            self.logger.debug(f"ğŸ” å¼€å§‹OCRè¯†åˆ«: {pdf_path.name}")
            
            # è½¬æ¢PDFä¸ºå›¾åƒ
            images = self._pdf2image(str(pdf_path), dpi=200)
            text_all = ""
            
            for idx, img in enumerate(images, 1):
                self.logger.debug(f"æ­£åœ¨è¯†åˆ«ç¬¬ {idx}/{len(images)} é¡µ...")
                try:
                    # ä½¿ç”¨ä¸­è‹±æ–‡æ··åˆè¯†åˆ«
                    text = self._pytesseract.image_to_string(img, lang='chi_sim+eng')
                    text_all += f"\n---- ç¬¬{idx}é¡µ ----\n{text}\n"
                except Exception as e:
                    self.logger.warning(f"ç¬¬{idx}é¡µOCRè¯†åˆ«å¤±è´¥: {e}")
                    continue
            
            self.logger.debug(f"âœ… OCRè¯†åˆ«å®Œæˆï¼Œæå–äº† {len(text_all)} ä¸ªå­—ç¬¦")
            return text_all
            
        except Exception as e:
            self.logger.error(f"âŒ OCRè¯†åˆ«å¤±è´¥: {e}")
            return ""
    
    def _identify_key_sections(self, text: str) -> Dict[str, str]:
        """
        è¯†åˆ«æ–‡æœ¬ä¸­çš„å…³é”®ç« èŠ‚
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            ç« èŠ‚å­—å…¸ {ç« èŠ‚å: ç« èŠ‚å†…å®¹}
        """
        sections = {}
        
        # å®šä¹‰ç« èŠ‚å…³é”®è¯æ¨¡å¼
        section_patterns = {
            'abstract': [r'abstract', r'æ‘˜è¦', r'summary'],
            'introduction': [r'introduction', r'å¼•è¨€', r'å‰è¨€', r'èƒŒæ™¯'],
            'methods': [r'methods?', r'methodology', r'ææ–™ä¸æ–¹æ³•', r'æ–¹æ³•'],
            'results': [r'results?', r'findings', r'ç»“æœ'],
            'discussion': [r'discussion', r'è®¨è®º', r'åˆ†æ'],
            'conclusion': [r'conclusions?', r'ç»“è®º', r'æ€»ç»“']
        }
        
        text_lower = text.lower()
        
        for section_name, patterns in section_patterns.items():
            for pattern in patterns:
                # æŸ¥æ‰¾ç« èŠ‚æ ‡é¢˜
                matches = re.finditer(rf'\b{pattern}\b', text_lower, re.IGNORECASE)
                
                for match in matches:
                    start_pos = match.start()
                    
                    # ç¡®ä¿æ˜¯ç« èŠ‚æ ‡é¢˜ï¼ˆå‰é¢æœ‰æ¢è¡Œæˆ–å¼€å¤´ï¼‰
                    if start_pos > 0 and text[start_pos-1] not in '\n\r':
                        continue
                    
                    # æŸ¥æ‰¾ç« èŠ‚ç»“æŸä½ç½®
                    end_pos = len(text)
                    for other_section, other_patterns in section_patterns.items():
                        if other_section == section_name:
                            continue
                        for other_pattern in other_patterns:
                            other_matches = re.finditer(rf'\b{other_pattern}\b', 
                                                      text_lower[start_pos+100:], 
                                                      re.IGNORECASE)
                            for other_match in other_matches:
                                candidate_end = start_pos + 100 + other_match.start()
                                if candidate_end < end_pos:
                                    end_pos = candidate_end
                                break
                    
                    # æå–ç« èŠ‚å†…å®¹
                    section_content = text[start_pos:end_pos].strip()
                    if len(section_content) > 100:  # æœ€å°ç« èŠ‚é•¿åº¦
                        sections[section_name] = section_content
                        break
                
                if section_name in sections:
                    break
        
        return sections
    
    def filter_and_optimize_text(self, text: str, max_length: Optional[int] = None) -> str:
        """
        æ™ºèƒ½ç­›é€‰å’Œä¼˜åŒ–æ–‡æœ¬å†…å®¹
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            max_length: æœ€å¤§é•¿åº¦é™åˆ¶
            
        Returns:
            ä¼˜åŒ–åçš„æ–‡æœ¬
        """
        if not text or not text.strip():
            return ""
        
        max_length = max_length or self.text_limit
        
        if len(text) <= max_length:
            return text
        
        self.logger.debug(f"æ–‡æœ¬è¿‡é•¿ï¼ˆ{len(text)}å­—ç¬¦ï¼‰ï¼Œå¼€å§‹æ™ºèƒ½ä¼˜åŒ–...")
        
        # è¯†åˆ«å…³é”®ç« èŠ‚
        key_sections = self._identify_key_sections(text)
        
        if not key_sections:
            # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°ç« èŠ‚ï¼Œä½¿ç”¨å¤´å°¾æˆªå–
            head_length = min(max_length // 3, 5000)
            tail_length = min(max_length - head_length, 3000)
            
            optimized_text = (text[:head_length] + 
                            "\n\n[... ä¸­é—´éƒ¨åˆ†å·²çœç•¥ ...]\n\n" + 
                            text[-tail_length:])
            
            self.logger.debug(f"ä½¿ç”¨å¤´å°¾æˆªå–ï¼Œä¿ç•™ {len(optimized_text)} å­—ç¬¦")
            return optimized_text
        
        # æŒ‰ä¼˜å…ˆçº§é€‰æ‹©ç« èŠ‚
        section_priority = ['abstract', 'introduction', 'methods', 'results', 'discussion', 'conclusion']
        selected_sections = []
        used_length = 0
        
        for section_name in section_priority:
            if section_name in key_sections:
                section_content = key_sections[section_name]
                if used_length + len(section_content) <= max_length:
                    selected_sections.append((section_name, section_content))
                    used_length += len(section_content)
                else:
                    # éƒ¨åˆ†æˆªå–
                    remaining_length = max_length - used_length
                    if remaining_length > 500:  # è‡³å°‘ä¿ç•™500å­—ç¬¦
                        truncated_content = section_content[:remaining_length-50] + "..."
                        selected_sections.append((section_name, truncated_content))
                    break
        
        # ç»„åˆä¼˜åŒ–åçš„æ–‡æœ¬
        optimized_text = ""
        for section_name, section_content in selected_sections:
            optimized_text += f"\n\n===== {section_name.upper()} =====\n{section_content}"
        
        self.logger.debug(f"æ™ºèƒ½ä¼˜åŒ–å®Œæˆï¼Œä¿ç•™ {len(optimized_text)} å­—ç¬¦")
        return optimized_text.strip()
    
    def extract_text_from_paper(self, paper: Dict[str, Any], text_limit: Optional[int] = None) -> Dict[str, Any]:
        """
        ä»å•ç¯‡æ–‡çŒ®ä¸­æå–æ–‡æœ¬
        
        Args:
            paper: æ–‡çŒ®è®°å½•
            text_limit: æ–‡æœ¬é•¿åº¦é™åˆ¶
            
        Returns:
            åŒ…å«å…¨æ–‡çš„æ–‡çŒ®è®°å½•
        """
        pmid = paper.get('PMID', '')
        title = paper.get('Title', 'Unknown')
        
        self.logger.debug(f"ğŸ” æå–æ–‡çŒ®æ–‡æœ¬: {pmid} - {title[:50]}...")
        
        full_text = ""
        text_source = "none"
        
        # ä¼˜å…ˆå°è¯•ä»PMCè·å–å…¨æ–‡
        if pmid:
            bioc_doc = self.fetch_bioc_document(pmid)
            if bioc_doc:
                meta_info = self.extract_meta_info(bioc_doc)
                full_text = self.extract_full_text_from_bioc(bioc_doc)
                if full_text:
                    full_text = meta_info + "\n\n" + full_text
                    text_source = "pmc"
                    self.logger.debug(f"âœ… ä»PMCè·å–å…¨æ–‡æˆåŠŸ: {len(full_text)} å­—ç¬¦")
        
        # å¦‚æœPMCæ²¡æœ‰å…¨æ–‡ï¼Œå°è¯•ä»PDFè·å–ï¼ˆå¦‚æœæä¾›äº†PDFè·¯å¾„ï¼‰
        if not full_text and 'pdf_path' in paper:
            pdf_path = paper['pdf_path']
            if pdf_path and Path(pdf_path).exists():
                full_text = self.extract_from_pdf(pdf_path)
                if full_text:
                    text_source = "pdf"
                    self.logger.debug(f"âœ… ä»PDFè·å–å…¨æ–‡æˆåŠŸ: {len(full_text)} å­—ç¬¦")
        
        # å¦‚æœéƒ½æ²¡æœ‰å…¨æ–‡ï¼Œä½¿ç”¨æ‘˜è¦
        if not full_text:
            abstract = paper.get('Abstract', '')
            if abstract and abstract != 'NA':
                full_text = f"æ ‡é¢˜: {title}\n\næ‘˜è¦: {abstract}"
                text_source = "abstract"
                self.logger.debug(f"âœ… ä½¿ç”¨æ‘˜è¦ä½œä¸ºæ–‡æœ¬: {len(full_text)} å­—ç¬¦")
        
        # ä¼˜åŒ–æ–‡æœ¬é•¿åº¦
        if full_text:
            full_text = self.filter_and_optimize_text(full_text, text_limit or self.text_limit)
        
        # æ›´æ–°æ–‡çŒ®è®°å½•
        paper_with_text = paper.copy()
        paper_with_text.update({
            'full_text': full_text,
            'text_source': text_source,
            'text_length': len(full_text) if full_text else 0
        })
        
        return paper_with_text
    
    def extract_batch(self, papers: List[Dict[str, Any]], 
                     max_workers: int = 4, 
                     text_limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æå–æ–‡çŒ®æ–‡æœ¬
        
        Args:
            papers: æ–‡çŒ®åˆ—è¡¨
            max_workers: æœ€å¤§å¹¶å‘æ•°
            text_limit: æ–‡æœ¬é•¿åº¦é™åˆ¶
            
        Returns:
            åŒ…å«å…¨æ–‡çš„æ–‡çŒ®åˆ—è¡¨
        """
        self.logger.info(f"ğŸ“„ å¼€å§‹æ‰¹é‡æå–æ–‡æœ¬ï¼Œå…± {len(papers)} ç¯‡æ–‡çŒ®")
        
        results = []
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_paper = {
                executor.submit(self.extract_text_from_paper, paper, text_limit): paper
                for paper in papers
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_paper):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    paper = future_to_paper[future]
                    pmid = paper.get('PMID', 'Unknown')
                    self.logger.error(f"âŒ æå–æ–‡çŒ® {pmid} çš„æ–‡æœ¬å¤±è´¥: {e}")
                    # æ·»åŠ å¤±è´¥è®°å½•
                    paper_with_error = paper.copy()
                    paper_with_error.update({
                        'full_text': '',
                        'text_source': 'error',
                        'text_length': 0,
                        'extraction_error': str(e)
                    })
                    results.append(paper_with_error)
        
        # ç»Ÿè®¡ç»“æœ
        successful = len([r for r in results if r.get('full_text')])
        self.logger.info(f"âœ… æ–‡æœ¬æå–å®Œæˆ: {successful}/{len(papers)} ç¯‡æˆåŠŸ")
        
        return results