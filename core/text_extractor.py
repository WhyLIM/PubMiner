# -*- coding: utf-8 -*-
"""
æ–‡æœ¬æå–æ¨¡å—

è´Ÿè´£ä» PMC å…¨æ–‡å’Œ PDF æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹
åŒ…å«æ™ºèƒ½ç« èŠ‚ç­›é€‰å’Œæ–‡æœ¬ä¼˜åŒ–åŠŸèƒ½
"""

import os
import json
import time
import requests
from pathlib import Path
from typing import Dict, List, Any, Optional, Union, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
import re

from utils.logger import LoggerMixin
from utils.file_handler import FileHandler
from utils.api_manager import api_manager

logger = logging.getLogger(__name__)


class TextExtractor(LoggerMixin):
    """ æ–‡æœ¬æå–å™¨ """

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–æ–‡æœ¬æå–å™¨
        
        Args:
            config: æå–é…ç½®
        """
        self.config = config
        self.text_limit = config.get('text_limit', 15000)
        self.section_filters = config.get('section_filters', [])
        self.exclude_sections = config.get('exclude_sections', [])
        self.key_section_ratio = config.get('key_section_ratio', {})

        # å»¶è¿Ÿå¯¼å…¥é‡é‡çº§åº“
        self._fitz = None
        self._pdf2image = None
        self._pytesseract = None
        self._PIL_Image = None

    def _import_pdf_libraries(self):
        """ å»¶è¿Ÿå¯¼å…¥ PDF å¤„ç†åº“ """
        if self._fitz is None:
            try:
                import fitz
                self._fitz = fitz
                self.logger.debug(" âœ… æˆåŠŸå¯¼å…¥ PyMuPDF åº“ ")
            except ImportError:
                self.logger.warning(" âš ï¸ PyMuPDF åº“æœªå®‰è£…ï¼Œ PDF å¤„ç†åŠŸèƒ½å°†å—é™ ")

        if self._pdf2image is None:
            try:
                from pdf2image import convert_from_path
                self._pdf2image = convert_from_path
                self.logger.debug(" âœ… æˆåŠŸå¯¼å…¥ pdf2image åº“ ")
            except ImportError:
                self.logger.warning(" âš ï¸ pdf2image åº“æœªå®‰è£…ï¼Œ OCR åŠŸèƒ½å°†å—é™ ")

        if self._pytesseract is None:
            try:
                import pytesseract
                self._pytesseract = pytesseract
                self.logger.debug(" âœ… æˆåŠŸå¯¼å…¥ pytesseract åº“ ")
            except ImportError:
                self.logger.warning(" âš ï¸ pytesseract åº“æœªå®‰è£…ï¼Œ OCR åŠŸèƒ½å°†å—é™ ")

        if self._PIL_Image is None:
            try:
                from PIL import Image
                self._PIL_Image = Image
                self.logger.debug(" âœ… æˆåŠŸå¯¼å…¥ PIL åº“ ")
            except ImportError:
                self.logger.warning(" âš ï¸ PIL åº“æœªå®‰è£…ï¼Œå›¾åƒå¤„ç†åŠŸèƒ½å°†å—é™ ")

    def fetch_bioc_document(
            self,
            pmid: str,
            format_type: str = "json",
            encoding: str = "unicode") -> Optional[Dict[str, Any]]:
        """
        ä» NCBI BioC API è·å–ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®æ•°æ®
        
        Args:
            pmid: æ–‡çŒ® PMID
            format_type: è¿”å›æ ¼å¼ï¼Œ'xml' æˆ– 'json'
            encoding: ç¼–ç æ ¼å¼ï¼Œ'unicode' æˆ– 'ascii'
            
        Returns:
            BioC æ–‡æ¡£çš„ JSON å¯¹è±¡ï¼Œå¤±è´¥è¿”å› None
        """
        url = f"https://www.ncbi.nlm.nih.gov/research/bionlp/RESTful/pmcoa.cgi/BioC_{format_type}/{pmid}/{encoding}"

        try:
            self.logger.debug(f" æ­£åœ¨è·å– PMID {pmid} çš„ BioC æ•°æ® ...")

            response = api_manager.get(
                url,
                timeout=30,
                api_name='pubmed_no_key'  # BioC API æ²¡æœ‰ key é™åˆ¶ï¼Œä½¿ç”¨è¾ƒå®½æ¾çš„é™æµ
            )

            if response.status_code == 200:
                data = response.json()
                if isinstance(data, list) and len(data) > 0:
                    self.logger.debug(f" âœ… æˆåŠŸè·å– PMID {pmid} çš„ BioC æ•°æ® ")
                    return data[0]
                else:
                    self.logger.warning(f" âš ï¸ PMID {pmid} çš„ BioC æ•°æ®æ ¼å¼å¼‚å¸¸ ")
                    return None
            else:
                self.logger.warning(
                    f" âš ï¸ è·å– PMID {pmid} çš„ BioC æ•°æ®å¤±è´¥ï¼ŒçŠ¶æ€ç  : {response.status_code}"
                )
                return None

        except Exception as e:
            self.logger.warning(f" âš ï¸ è·å– PMID {pmid} çš„ BioC æ•°æ®æ—¶å‡ºé”™ : {e}")
            return None

    def extract_meta_info(self, bioc_document: Dict[str, Any]) -> str:
        """
        ä» BioC æ–‡æ¡£ä¸­æå–å…ƒæ•°æ®ä¿¡æ¯
        
        Args:
            bioc_document: BioC æ–‡æ¡£ JSON
            
        Returns:
            æ ¼å¼åŒ–çš„å…ƒæ•°æ®å­—ç¬¦ä¸²
        """
        try:
            for passage in bioc_document["documents"][0]["passages"]:
                if passage["infons"]["section_type"] == "TITLE":
                    metadata = passage["infons"]

                    # å¤„ç†å…³é”®è¯
                    keywords = metadata.get('kwd', 'N/A')

                    # å¤„ç†ä½œè€…ä¿¡æ¯
                    authors = [
                        value for key, value in metadata.items()
                        if key.startswith('name_')
                    ]
                    formatted_authors = []
                    for author in authors:
                        parts = author.split(';')
                        surname = parts[0].split(
                            ':')[1] if ':' in parts[0] else parts[0]
                        if len(parts) > 1 and ':' in parts[1]:
                            given_names = parts[1].split(':')[1]
                            formatted_name = f"{given_names} {surname}"
                        else:
                            formatted_name = surname
                        formatted_authors.append(formatted_name)

                    # è·å–å…¶ä»–å…ƒæ•°æ®å­—æ®µ
                    doi = metadata.get('article-id_doi', 'N/A')
                    pmid = metadata.get('article-id_pmid', 'N/A')
                    pmcid = metadata.get('article-id_pmc', 'N/A')
                    year = metadata.get('year', 'N/A')
                    source = metadata.get('source', 'N/A')
                    volume = metadata.get('volume', 'N/A')
                    issue = metadata.get('issue', 'N/A')

                    # æ ¼å¼åŒ–å…ƒæ•°æ®æ–‡æœ¬
                    meta_text = f""" æ ‡é¢˜ : {passage['text']}
                                     DOI: {doi}
                                     PMID: {pmid}
                                     PMCID: PMC{pmcid}
                                     å¹´ä»½ : {year}
                                     æœŸåˆŠ : {source}, å·å· {volume}, æœŸå· {issue}
                                     å…³é”®è¯ : {keywords}
                                     ä½œè€… : {', '.join(formatted_authors)}"""

                    return meta_text

        except Exception as e:
            self.logger.warning(f" æå–å…ƒæ•°æ®ä¿¡æ¯æ—¶å‡ºé”™ : {e}")

        return " å…ƒæ•°æ®æå–å¤±è´¥ "

    def extract_full_text_from_bioc(self, bioc_document: Dict[str,
                                                              Any]) -> str:
        """
        ä» BioC æ–‡æ¡£ä¸­æå–å…¨æ–‡å†…å®¹
        
        Args:
            bioc_document: BioC æ–‡æ¡£ JSON
            
        Returns:
            å…¨æ–‡å†…å®¹å­—ç¬¦ä¸²
        """
        try:
            # è·å–æ‰€æœ‰ç« èŠ‚ç±»å‹
            section_types = []
            for passage in bioc_document["documents"][0]["passages"]:
                section_type = passage["infons"]["section_type"]
                if (section_type not in section_types
                        and section_type not in self.exclude_sections):
                    section_types.append(section_type)

            self.logger.debug(f" æå–ç« èŠ‚ç±»å‹ : {section_types}")

            # æŒ‰ç« èŠ‚æå–æ–‡æœ¬
            full_text = ""
            section_texts = {}

            for section_type in section_types:
                section_text = ""
                for passage in bioc_document["documents"][0]["passages"]:
                    if passage["infons"]["section_type"] == section_type:
                        section_text += passage["text"] + "\n\n"

                if section_text.strip():
                    section_texts[section_type] = section_text
                    full_text += f"\n\n===== {section_type} =====\n{section_text}"

            return full_text.strip()

        except Exception as e:
            self.logger.error(f" ä» BioC æ–‡æ¡£æå–å…¨æ–‡æ—¶å‡ºé”™ : {e}")
            return ""

    def extract_from_pdf(self,
                         pdf_path: Union[str, Path],
                         min_chars: int = 1000) -> str:
        """
        ä» PDF æ–‡ä»¶æå–æ–‡æœ¬
        
        Args:
            pdf_path: PDF æ–‡ä»¶è·¯å¾„
            min_chars: æœ€å°å­—ç¬¦æ•°é˜ˆå€¼
            
        Returns:
            æå–çš„æ–‡æœ¬å†…å®¹
        """
        self._import_pdf_libraries()

        if self._fitz is None:
            self.logger.error(" âŒ PyMuPDF åº“æœªå®‰è£…ï¼Œæ— æ³•å¤„ç† PDF æ–‡ä»¶ ")
            return ""

        pdf_path = Path(pdf_path)

        if not pdf_path.exists():
            self.logger.error(f" âŒ PDF æ–‡ä»¶ä¸å­˜åœ¨ : {pdf_path}")
            return ""

        try:
            self.logger.debug(f" ğŸ” å°è¯•ç›´æ¥æå– PDF æ–‡æœ¬ : {pdf_path.name}")

            # å°è¯•ç›´æ¥æå–æ–‡æœ¬
            doc = self._fitz.open(str(pdf_path))
            text = "\n".join([page.get_text() for page in doc])
            doc.close()

            effective_chars = len(''.join(text.split()))
            zh_count = sum('\u4e00' <= c <= '\u9fff' for c in text)
            en_count = sum(c.isalpha() for c in text)

            self.logger.debug(
                f" æå–åˆ° {len(text)} ä¸ªå­—ç¬¦ï¼ˆæœ‰æ•ˆ : {effective_chars}, ä¸­æ–‡ : {zh_count}, è‹±æ–‡ : {en_count}ï¼‰"
            )

            # åˆ¤æ–­æå–è´¨é‡
            if (effective_chars >= min_chars
                    or (effective_chars > 500 and
                        (zh_count > 100 or en_count > 300))):
                self.logger.debug(f" âœ… PDF æ–‡æœ¬æå–æˆåŠŸ ")
                return text

            # å¦‚æœæ–‡æœ¬è´¨é‡ä¸å¤Ÿï¼Œå°è¯• OCR
            self.logger.debug(f" âš ï¸ æå–æ–‡æœ¬è´¨é‡ä¸è¶³ï¼Œå°è¯• OCR...")
            return self._ocr_from_pdf(pdf_path)

        except Exception as e:
            self.logger.error(f" âŒ PDF æ–‡æœ¬æå–å¤±è´¥ : {e}")
            return ""

    def _ocr_from_pdf(self, pdf_path: Path) -> str:
        """
        ä½¿ç”¨ OCR ä» PDF æå–æ–‡æœ¬
        
        Args:
            pdf_path: PDF æ–‡ä»¶è·¯å¾„
            
        Returns:
            OCR è¯†åˆ«çš„æ–‡æœ¬
        """
        if (self._pdf2image is None or self._pytesseract is None
                or self._PIL_Image is None):
            self.logger.warning(" âš ï¸ OCR ç›¸å…³åº“æœªå®‰è£…ï¼Œè·³è¿‡ OCR å¤„ç† ")
            return ""

        try:
            self.logger.debug(f" ğŸ” å¼€å§‹ OCR è¯†åˆ« : {pdf_path.name}")

            # è½¬æ¢ PDF ä¸ºå›¾åƒ
            images = self._pdf2image(str(pdf_path), dpi=200)
            text_all = ""

            for idx, img in enumerate(images, 1):
                self.logger.debug(f" æ­£åœ¨è¯†åˆ«ç¬¬ {idx}/{len(images)} é¡µ ...")
                try:
                    # ä½¿ç”¨ä¸­è‹±æ–‡æ··åˆè¯†åˆ«
                    text = self._pytesseract.image_to_string(
                        img, lang='chi_sim+eng')
                    text_all += f"\n---- ç¬¬ {idx} é¡µ ----\n{text}\n"
                except Exception as e:
                    self.logger.warning(f" ç¬¬ {idx} é¡µ OCR è¯†åˆ«å¤±è´¥ : {e}")
                    continue

            self.logger.debug(f" âœ… OCR è¯†åˆ«å®Œæˆï¼Œæå–äº† {len(text_all)} ä¸ªå­—ç¬¦ ")
            return text_all

        except Exception as e:
            self.logger.error(f" âŒ OCR è¯†åˆ«å¤±è´¥ : {e}")
            return ""

    def _identify_key_sections(self, text: str) -> Dict[str, str]:
        """
        è¯†åˆ«æ–‡æœ¬ä¸­çš„å…³é”®ç« èŠ‚
        
        Args:
            text: åŸå§‹æ–‡æœ¬ (string)
        
        Returns:
            ç« èŠ‚å­—å…¸ Dict[str, str]: {section_name: section_content}
        """
        # === 1. æ ‡å‡†åŒ–æ–‡æœ¬ ===
        text = re.sub(r'\r', '\n', text)             # æ ‡å‡†åŒ–æ¢è¡Œç¬¦
        text = re.sub(r'\n{2,}', '\n\n', text)       # æŠ˜å å¤šä½™çš„ç©ºè¡Œ
        text_lower = text.lower()
        
        # === 2. å®šä¹‰éƒ¨åˆ†å…³é”®è¯æ¨¡å¼ ===
        section_patterns = {
            "abstract": [r"abstract", r"summary"],
            "introduction": [r"introduction", r"background", r"objective[s]?", r"aim[s]?"],
            "methods": [r"materials and methods", r"methods?", r"methodology", r"study design", r"experimental procedures"],
            "results": [r"results?", r"findings", r"outcomes", r"observations"],
            "discussion": [r"discussion", r"interpretation", r"analysis"],
            "conclusion": [r"conclusion[s]?", r"summary", r"final remarks"],
            "acknowledgments": [r"acknowledg?ments?", r"funding", r"support"],
            "references": [r"references", r"bibliography"],
        }

        # === 3. å®šä½æ‰€æœ‰ç« èŠ‚æ ‡é¢˜ ===
        matches: List[Tuple[str, int]] = []
        for name, patterns in section_patterns.items():
            for pat in patterns:
                # åŒ¹é…æ ‡é¢˜å¦‚ "Introduction", "Introduction:"ï¼Œæˆ–è¡Œé¦–
                regex = rf"( ^ |\n)\s*{pat}\s*[:.]?\s*(\n|$)"
                for m in re.finditer(regex, text_lower):
                    matches.append((name, m.start()))

        if not matches:
            return {}

        # === 4. æŒ‰ä½ç½®æ’åº ===
        matches.sort(key=lambda x: x[1])

        # === 5. æå–ç« èŠ‚ ===
        sections: Dict[str, str] = {}
        for i, (name, start_pos) in enumerate(matches):
            end_pos = matches[i + 1][1] if i + 1 < len(matches) else len(text)
            section_text = text[start_pos:end_pos].strip()
            # è¿‡æ»¤è¯¯æŠ¥çš„æœ€å°å†…å®¹é•¿åº¦ï¼ˆé™ä½é˜ˆå€¼ä»¥æé«˜å…¼å®¹æ€§ï¼‰
            if len(section_text) > 20:  # ä» 100 é™ä½åˆ° 20 ï¼Œæé«˜å…¼å®¹æ€§
                sections[name] = section_text

        return sections

    def filter_and_optimize_text(self,
                                 text: str,
                                 max_length: Optional[int] = None) -> str:
        """
        æ™ºèƒ½ç­›é€‰å’Œä¼˜åŒ–æ–‡æœ¬å†…å®¹
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            max_length: æœ€å¤§é•¿åº¦é™åˆ¶
            
        Returns:
            ä¼˜åŒ–åçš„æ–‡æœ¬
        """
        if not text or not text.strip():
            return ""

        max_length = max_length or self.text_limit

        if len(text) <= max_length:
            return text

        self.logger.debug(f" æ–‡æœ¬è¿‡é•¿ï¼ˆ{len(text)} å­—ç¬¦ï¼‰ï¼Œå¼€å§‹æ™ºèƒ½ä¼˜åŒ– ...")

        # è¯†åˆ«å…³é”®ç« èŠ‚
        key_sections = self._identify_key_sections(text)

        if not key_sections:
            # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°ç« èŠ‚ï¼Œä½¿ç”¨å¤´å°¾æˆªå–
            head_length = min(max_length // 3, 5000)
            tail_length = min(max_length - head_length, 3000)

            optimized_text = (text[:head_length] +
                              "\n\n[... ä¸­é—´éƒ¨åˆ†å·²çœç•¥ ...]\n\n" +
                              text[-tail_length:])

            self.logger.debug(f" ä½¿ç”¨å¤´å°¾æˆªå–ï¼Œä¿ç•™ {len(optimized_text)} å­—ç¬¦ ")
            return optimized_text

        # æŒ‰ä¼˜å…ˆçº§é€‰æ‹©ç« èŠ‚
        section_priority = [
            'abstract', 'introduction', 'methods', 'results', 'discussion',
            'conclusion'
        ]
        selected_sections = []
        used_length = 0

        for section_name in section_priority:
            if section_name in key_sections:
                section_content = key_sections[section_name]
                # è®¡ç®—æ·»åŠ åˆ†éš”ç¬¦åçš„æ€»é•¿åº¦ï¼ˆåŒ…æ‹¬æ¢è¡Œç¬¦ï¼‰
                separator_length = len("\\n\\n===== " + section_name.upper() + " =====\\n")
                total_section_length = len(section_content) + separator_length
                
                if used_length + total_section_length <= max_length:
                    selected_sections.append((section_name, section_content))
                    used_length += total_section_length
                else:
                    # éƒ¨åˆ†æˆªå–
                    remaining_length = max_length - used_length - separator_length
                    if remaining_length > 100:  # è‡³å°‘ä¿ç•™ 100 å­—ç¬¦
                        truncated_content = section_content[:remaining_length - 3] + "..."
                        selected_sections.append(
                            (section_name, truncated_content))
                        used_length += len(truncated_content) + separator_length
                    break

        # ç»„åˆä¼˜åŒ–åçš„æ–‡æœ¬
        optimized_text = ""
        for section_name, section_content in selected_sections:
            optimized_text += f"\n\n===== {section_name.upper()} =====\n{section_content}"

        self.logger.debug(f" æ™ºèƒ½ä¼˜åŒ–å®Œæˆï¼Œä¿ç•™ {len(optimized_text)} å­—ç¬¦ ")
        return optimized_text.strip()

    def extract_text_from_paper(
            self,
            paper: Dict[str, Any],
            text_limit: Optional[int] = None) -> Dict[str, Any]:
        """
        ä»å•ç¯‡æ–‡çŒ®ä¸­æå–æ–‡æœ¬
        
        Args:
            paper: æ–‡çŒ®è®°å½•
            text_limit: æ–‡æœ¬é•¿åº¦é™åˆ¶
            
        Returns:
            åŒ…å«å…¨æ–‡çš„æ–‡çŒ®è®°å½•
        """
        pmid = paper.get('PMID', '')
        title = paper.get('Title', 'Unknown')

        self.logger.debug(f" ğŸ” æå–æ–‡çŒ®æ–‡æœ¬ : {pmid} - {title[:50]}...")

        full_text = ""
        text_source = "none"

        # ä¼˜å…ˆå°è¯•ä» PMC è·å–å…¨æ–‡
        if pmid:
            bioc_doc = self.fetch_bioc_document(pmid)
            if bioc_doc:
                meta_info = self.extract_meta_info(bioc_doc)
                full_text = self.extract_full_text_from_bioc(bioc_doc)
                if full_text:
                    full_text = meta_info + "\n\n" + full_text
                    text_source = "pmc"
                    self.logger.debug(
                        f" âœ… ä» PMC è·å–å…¨æ–‡æˆåŠŸ : {len(full_text)} å­—ç¬¦ ")

        # å¦‚æœ PMC æ²¡æœ‰å…¨æ–‡ï¼Œå°è¯•ä» PDF è·å–ï¼ˆå¦‚æœæä¾›äº† PDF è·¯å¾„ï¼‰
        if not full_text and 'pdf_path' in paper:
            pdf_path = paper['pdf_path']
            if pdf_path and Path(pdf_path).exists():
                full_text = self.extract_from_pdf(pdf_path)
                if full_text:
                    text_source = "pdf"
                    self.logger.debug(
                        f" âœ… ä» PDF è·å–å…¨æ–‡æˆåŠŸ : {len(full_text)} å­—ç¬¦ ")

        # å¦‚æœéƒ½æ²¡æœ‰å…¨æ–‡ï¼Œä½¿ç”¨æ‘˜è¦
        if not full_text:
            abstract = paper.get('Abstract', '')
            if abstract and abstract != 'NA':
                full_text = f" æ ‡é¢˜ : {title}\n\n æ‘˜è¦ : {abstract}"
                text_source = "abstract"
                self.logger.debug(f" âœ… ä½¿ç”¨æ‘˜è¦ä½œä¸ºæ–‡æœ¬ : {len(full_text)} å­—ç¬¦ ")

        # ä¼˜åŒ–æ–‡æœ¬é•¿åº¦
        if full_text:
            full_text = self.filter_and_optimize_text(
                full_text, text_limit or self.text_limit)

        # æ›´æ–°æ–‡çŒ®è®°å½•
        paper_with_text = paper.copy()
        paper_with_text.update({
            'full_text':
            full_text,
            'text_source':
            text_source,
            'text_length':
            len(full_text) if full_text else 0
        })

        return paper_with_text

    def extract_batch(
            self,
            papers: List[Dict[str, Any]],
            max_workers: int = 4,
            text_limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æå–æ–‡çŒ®æ–‡æœ¬
        
        Args:
            papers: æ–‡çŒ®åˆ—è¡¨
            max_workers: æœ€å¤§å¹¶å‘æ•°
            text_limit: æ–‡æœ¬é•¿åº¦é™åˆ¶
            
        Returns:
            åŒ…å«å…¨æ–‡çš„æ–‡çŒ®åˆ—è¡¨
        """
        self.logger.info(f" ğŸ“„ å¼€å§‹æ‰¹é‡æå–æ–‡æœ¬ï¼Œå…± {len(papers)} ç¯‡æ–‡çŒ® ")

        results = []

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_paper = {
                executor.submit(self.extract_text_from_paper, paper, text_limit):
                paper
                for paper in papers
            }

            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_paper):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    paper = future_to_paper[future]
                    pmid = paper.get('PMID', 'Unknown')
                    self.logger.error(f" âŒ æå–æ–‡çŒ® {pmid} çš„æ–‡æœ¬å¤±è´¥ : {e}")
                    # æ·»åŠ å¤±è´¥è®°å½•
                    paper_with_error = paper.copy()
                    paper_with_error.update({
                        'full_text': '',
                        'text_source': 'error',
                        'text_length': 0,
                        'extraction_error': str(e)
                    })
                    results.append(paper_with_error)

        # ç»Ÿè®¡ç»“æœ
        successful = len([r for r in results if r.get('full_text')])
        self.logger.info(f" âœ… æ–‡æœ¬æå–å®Œæˆ : {successful}/{len(papers)} ç¯‡æˆåŠŸ ")

        return results
