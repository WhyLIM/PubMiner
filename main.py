#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PubMiner - æ¨¡å—åŒ–æ–‡çŒ®åˆ†æå·¥å…·
ä¸»ç¨‹åºå…¥å£

åŠŸèƒ½ï¼š
1. è·å–PubMedæ–‡çŒ®åŸºæœ¬ä¿¡æ¯
2. æå–å…¨æ–‡å†…å®¹ï¼ˆPMC/PDFï¼‰
3. åŸºäºå¤§æ¨¡å‹çš„ç»“æ„åŒ–ä¿¡æ¯æå–
4. ç”Ÿæˆæ ‡å‡†åŒ–CSVæŠ¥å‘Š
"""

import sys
import argparse
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from core.config_manager import ConfigManager
from core.pubmed_fetcher import PubMedFetcher
from core.text_extractor import TextExtractor
from core.llm_analyzer import LLMAnalyzer
from core.data_processor import DataProcessor
from core.query_manager import QueryManager
from utils.logger import setup_logger


class PubMiner:
    """PubMiner ä¸»ç±» - æä¾›ç¼–ç¨‹æ¥å£"""

    def __init__(self, config_path=None, llm_provider='deepseek'):
        """
        åˆå§‹åŒ–PubMiner
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            llm_provider: LLMæä¾›å•†
        """
        # å¦‚æœæ²¡æœ‰æŒ‡å®šé…ç½®è·¯å¾„ï¼Œä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„é…ç½®
        if config_path is None:
            project_root = Path(__file__).parent
            config_path = project_root / 'config' / 'default_config.json'

        self.config_manager = ConfigManager(str(config_path))
        self.llm_provider = llm_provider
        self.logger = setup_logger(logging.INFO, Path('logs'))

        # åˆå§‹åŒ–ç»„ä»¶
        # åˆå¹¶pubmedé…ç½®å’Œcitation_detailsé…ç½®ä¼ é€’ç»™PubMedFetcher
        pubmed_config = self.config_manager.get_pubmed_config()
        output_config = self.config_manager.get_output_config()
        pubmed_config.update(
            {'citation_details': output_config.get('citation_details', {})})

        self.fetcher = PubMedFetcher(pubmed_config)
        self.extractor = TextExtractor(
            self.config_manager.get_extraction_config())
        self.analyzer = LLMAnalyzer(
            self.config_manager.get_llm_config(llm_provider))
        self.processor = DataProcessor(output_config)
        self.query_manager = QueryManager(self.config_manager)

        self.logger.info("âœ… PubMiner åˆå§‹åŒ–å®Œæˆ")

    def analyze_by_query(self,
                         query,
                         template_name='standard',
                         max_results=50,
                         include_fulltext=True,
                         max_workers=4,
                         language=None,
                         custom_template_file=None):
        """
        æ ¹æ®æŸ¥è¯¢è¯åˆ†ææ–‡çŒ®
        
        Args:
            query: PubMedæŸ¥è¯¢è¯
            template_name: æå–æ¨¡æ¿åç§°
            max_results: æœ€å¤§ç»“æœæ•°
            include_fulltext: æ˜¯å¦åŒ…å«å…¨æ–‡
            max_workers: å¹¶å‘æ•°
            language: è¾“å‡ºè¯­è¨€ (Chinese, English, etc.)ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
            custom_template_file: è‡ªå®šä¹‰æ¨¡æ¿æ–‡ä»¶è·¯å¾„
            
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        # å¦‚æœæœªæŒ‡å®šè¯­è¨€ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤è¯­è¨€
        if language is None:
            language = self.config_manager.get_default_language()
        else:
            language = self.config_manager.normalize_language(language)

        self.logger.info(f"ğŸ” å¼€å§‹æŸ¥è¯¢åˆ†æ: {query}")
        self.logger.info(f"ğŸŒ è¾“å‡ºè¯­è¨€: {language}")

        # 1. è·å–æ–‡çŒ®åŸºæœ¬ä¿¡æ¯
        papers = self.fetcher.fetch_by_query(query, max_results=max_results)
        self.logger.info(f"ğŸ“š è·å–åˆ° {len(papers)} ç¯‡æ–‡çŒ®")

        if not papers:
            return []

        # 2. æå–å…¨æ–‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if include_fulltext:
            papers = self.extractor.extract_batch(papers,
                                                  max_workers=max_workers)
            papers = [p for p in papers if p.get('full_text')]
            self.logger.info(f"ğŸ“„ æˆåŠŸæå– {len(papers)} ç¯‡æ–‡çŒ®å…¨æ–‡")

        # 3. LLMåˆ†æ
        if custom_template_file:
            # åŠ è½½è‡ªå®šä¹‰æ¨¡æ¿æ–‡ä»¶
            import json
            with open(custom_template_file, 'r', encoding='utf-8') as f:
                template = json.load(f)
        else:
            template = self.config_manager.get_extraction_template(
                template_name)
        analyzed_papers = self.analyzer.analyze_batch(papers,
                                                      template,
                                                      max_workers=max_workers,
                                                      language=language)

        self.logger.info(f"âœ… åˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(analyzed_papers)} ç¯‡æ–‡çŒ®")
        return analyzed_papers

    def analyze_by_pmids(self,
                         pmids,
                         template_name='standard',
                         include_fulltext=True,
                         max_workers=4,
                         language=None):
        """
        æ ¹æ®PMIDåˆ—è¡¨åˆ†ææ–‡çŒ®
        
        Args:
            pmids: PMIDåˆ—è¡¨
            template_name: æå–æ¨¡æ¿åç§°
            include_fulltext: æ˜¯å¦åŒ…å«å…¨æ–‡
            max_workers: å¹¶å‘æ•°
            language: è¾“å‡ºè¯­è¨€ï¼ˆNone æ—¶ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼ï¼‰
            
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        # å¦‚æœæœªæŒ‡å®šè¯­è¨€ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤è¯­è¨€
        if language is None:
            language = self.config_manager.get_default_language()

        self.logger.info(f"ğŸ” å¼€å§‹ PMID åˆ†æ: {len(pmids)} ç¯‡æ–‡çŒ®")
        self.logger.info(f"ğŸŒ è¾“å‡ºè¯­è¨€: {language}")

        # 1. è·å–æ–‡çŒ®åŸºæœ¬ä¿¡æ¯
        papers = self.fetcher.fetch_by_pmid_list(pmids)
        self.logger.info(f"ğŸ“š è·å–åˆ° {len(papers)} ç¯‡æ–‡çŒ®")

        if not papers:
            return []

        # 2. æå–å…¨æ–‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if include_fulltext:
            papers = self.extractor.extract_batch(papers,
                                                  max_workers=max_workers)
            papers = [p for p in papers if p.get('full_text')]
            self.logger.info(f"ğŸ“„ æˆåŠŸæå– {len(papers)} ç¯‡æ–‡çŒ®å…¨æ–‡")

        # 3. LLM åˆ†æ
        template = self.config_manager.get_extraction_template(template_name)
        analyzed_papers = self.analyzer.analyze_batch(papers,
                                                      template,
                                                      max_workers=max_workers,
                                                      language=language)

        self.logger.info(f"âœ… åˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(analyzed_papers)} ç¯‡æ–‡çŒ®")
        return analyzed_papers

    def save_results(self, results, output_name='analysis_results'):
        """
        ä¿å­˜åˆ†æç»“æœ
        
        Args:
            results: åˆ†æç»“æœåˆ—è¡¨
            output_name: è¾“å‡ºæ–‡ä»¶åå‰ç¼€
        """
        from datetime import datetime
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = Path('results') / f'{output_name}_{timestamp}.csv'

        # ä½¿ç”¨æ ‡å‡†æ¨¡æ¿ï¼ˆè¿™é‡Œéœ€è¦æ”¹è¿›ä»¥æ”¯æŒåŠ¨æ€æ¨¡æ¿ï¼‰
        template = self.config_manager.get_extraction_template('standard')
        self.processor.generate_csv(results, template, output_path)

        self.logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        return output_path

    def get_available_templates(self):
        """è·å–å¯ç”¨çš„æå–æ¨¡æ¿åˆ—è¡¨"""
        templates = self.config_manager.get_extraction_templates()
        return list(templates.keys())

    def create_custom_template(self,
                               fields,
                               template_name,
                               template_description="Custom template"):
        """
        åˆ›å»ºè‡ªå®šä¹‰æ¨¡æ¿
        
        Args:
            fields: å­—æ®µå®šä¹‰åˆ—è¡¨
            template_name: æ¨¡æ¿åç§°
            template_description: æ¨¡æ¿æè¿°
        """
        from extractors.custom_extractor import CustomExtractor
        extractor = CustomExtractor(self.config_manager.get_config())
        template = extractor.create_template_from_fields(
            fields, template_description)

        # è¿™é‡Œå¯ä»¥æ·»åŠ ä¿å­˜æ¨¡æ¿çš„é€»è¾‘
        return template

    def execute_batch_queries(self, config_file):
        """
        æ‰§è¡Œæ‰¹é‡æŸ¥è¯¢ä»»åŠ¡
        
        Args:
            config_file: æŸ¥è¯¢é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        return self.query_manager.execute_batch_queries(config_file, self)

    def create_query_config_example(self,
                                    output_file="query_config_example.json"):
        """
        åˆ›å»ºæŸ¥è¯¢é…ç½®ç¤ºä¾‹æ–‡ä»¶
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        self.query_manager.create_example_config(output_file)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='PubMiner - æ¨¡å—åŒ–æ–‡çŒ®åˆ†æå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æŒ‰æŸ¥è¯¢è¯åˆ†ææ–‡çŒ®
  python main.py --query "covid-19 AND vaccine" --output results.csv
  
  # æŒ‰PMIDåˆ—è¡¨åˆ†æ
  python main.py --pmids 12345678,87654321 --output results.csv
  
  # ä½¿ç”¨è‡ªå®šä¹‰æå–æ¨¡æ¿
  python main.py --query "aging biomarker" --template aging_biomarker --output aging_results.csv
  
  # æŒ‡å®šå¤§æ¨¡å‹é…ç½®
  python main.py --query "cancer treatment" --llm-provider deepseek --output cancer_results.csv
        """)

    # è¾“å…¥å‚æ•°
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument('--query', type=str, help='PubMed æŸ¥è¯¢è¯')
    input_group.add_argument('--pmids', type=str, help='PMID åˆ—è¡¨ï¼Œé€—å·åˆ†éš”')
    input_group.add_argument('--pmid-file', type=str, help='åŒ…å« PMID åˆ—è¡¨çš„æ–‡ä»¶è·¯å¾„')
    input_group.add_argument('--batch-config', type=str, help='æ‰¹é‡æŸ¥è¯¢é…ç½®æ–‡ä»¶è·¯å¾„')
    input_group.add_argument('--create-query-example',
                             action='store_true',
                             help='åˆ›å»ºæŸ¥è¯¢é…ç½®ç¤ºä¾‹æ–‡ä»¶')

    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output', type=str, help='è¾“å‡º CSV æ–‡ä»¶è·¯å¾„ï¼ˆå•ä¸ªæŸ¥è¯¢æ—¶å¿…éœ€ï¼‰')
    parser.add_argument('--output-dir',
                        type=str,
                        default='output',
                        help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šoutputï¼‰')

    # å¤„ç†å‚æ•°
    parser.add_argument('--template',
                        type=str,
                        default='standard',
                        help='æå–æ¨¡æ¿ï¼ˆstandard/custom ç­‰ï¼Œé»˜è®¤ï¼šstandardï¼‰')
    parser.add_argument('--custom-fields', type=str, help='è‡ªå®šä¹‰å­—æ®µ JSON æ–‡ä»¶è·¯å¾„')

    # LLMå‚æ•°
    parser.add_argument('--llm-provider',
                        type=str,
                        default='deepseek',
                        choices=['openai', 'deepseek', 'qwen', 'volcengine'],
                        help='å¤§æ¨¡å‹æä¾›å•†ï¼ˆé»˜è®¤ï¼šdeepseekï¼‰')
    parser.add_argument('--llm-model', type=str, help='å…·ä½“æ¨¡å‹åç§°ï¼ˆè¦†ç›–é»˜è®¤é…ç½®ï¼‰')
    parser.add_argument('--api-key', type=str, help='API å¯†é’¥ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')

    # ä¼˜åŒ–å‚æ•°
    parser.add_argument('--max-workers',
                        type=int,
                        default=4,
                        help='æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤ï¼š4ï¼‰')
    parser.add_argument('--batch-size',
                        type=int,
                        default=10,
                        help='æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤ï¼š10ï¼‰')
    parser.add_argument('--text-limit',
                        type=int,
                        default=15000,
                        help='å•ç¯‡æ–‡çŒ®æ–‡æœ¬é•¿åº¦é™åˆ¶ï¼ˆé»˜è®¤ï¼š15000 å­—ç¬¦ï¼‰')

    # å…¶ä»–å‚æ•°
    parser.add_argument('--config',
                        type=str,
                        default='config/default_config.json',
                        help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šconfig/default_config.jsonï¼‰')
    parser.add_argument('--resume', action='store_true', help='æ–­ç‚¹ç»­ä¼ æ¨¡å¼')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    parser.add_argument('--dry-run',
                        action='store_true',
                        help='è¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸å®é™…è°ƒç”¨ APIï¼‰')

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()

    # è®¾ç½®æ—¥å¿—
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logger = setup_logger(log_level, Path('logs'))

    try:
        # å¤„ç†åˆ›å»ºæŸ¥è¯¢é…ç½®ç¤ºä¾‹çš„æƒ…å†µ
        if args.create_query_example:
            from core.query_manager import QueryManager
            config_manager = ConfigManager(args.config)
            query_manager = QueryManager(config_manager)
            output_file = args.output if args.output else "query_config_example.json"
            query_manager.create_example_config(output_file)
            return

        # éªŒè¯è¾“å‡ºæ–‡ä»¶å‚æ•°
        if not args.batch_config and not args.output:
            logger.error("âŒ é”™è¯¯: å•ä¸ªæŸ¥è¯¢æ¨¡å¼éœ€è¦æŒ‡å®š --output å‚æ•°")
            sys.exit(1)

        # å¤„ç†æ‰¹é‡æŸ¥è¯¢é…ç½®çš„æƒ…å†µ
        if args.batch_config:
            logger.info("ğŸš€ å¯åŠ¨ PubMiner æ‰¹é‡æŸ¥è¯¢æ¨¡å¼")
            logger.info(f"é…ç½®æ–‡ä»¶: {args.batch_config}")

            # åˆå§‹åŒ–PubMiner
            pubminer = PubMiner(args.config, args.llm_provider)

            # æ‰§è¡Œæ‰¹é‡æŸ¥è¯¢
            results = pubminer.execute_batch_queries(args.batch_config)

            logger.info("ğŸ‰ æ‰¹é‡æŸ¥è¯¢æ‰§è¡Œå®Œæˆï¼")
            return

        logger.info("ğŸš€ å¯åŠ¨ PubMiner æ–‡çŒ®åˆ†æå·¥å…·")
        logger.info(f"è¾“å‡ºç›®å½•: {args.output_dir}")
        logger.info(f"è¾“å‡ºæ–‡ä»¶: {args.output}")

        # 1. åŠ è½½é…ç½®
        logger.info("ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶...")
        config_manager = ConfigManager(args.config)

        # è¦†ç›–é…ç½®å‚æ•°
        if args.api_key:
            config_manager.set_api_key(args.llm_provider, args.api_key)
        if args.llm_model:
            config_manager.set_model(args.llm_provider, args.llm_model)

        # 2. è·å–æ–‡çŒ®åŸºæœ¬ä¿¡æ¯
        logger.info("ğŸ“š è·å–æ–‡çŒ®åŸºæœ¬ä¿¡æ¯...")
        fetcher = PubMedFetcher(config_manager.get_pubmed_config())

        if args.query:
            papers = fetcher.fetch_by_query(args.query, resume=args.resume)
        elif args.pmids:
            pmid_list = [pmid.strip() for pmid in args.pmids.split(',')]
            papers = fetcher.fetch_by_pmid_list(pmid_list, resume=args.resume)
        elif args.pmid_file:
            with open(args.pmid_file, 'r', encoding='utf-8') as f:
                pmid_list = [line.strip() for line in f if line.strip()]
            papers = fetcher.fetch_by_pmid_list(pmid_list, resume=args.resume)

        logger.info(f"âœ… è·å–åˆ° {len(papers)} ç¯‡æ–‡çŒ®çš„åŸºæœ¬ä¿¡æ¯")

        if not papers:
            logger.warning("âš ï¸ æœªè·å–åˆ°ä»»ä½•æ–‡çŒ®ï¼Œç¨‹åºé€€å‡º")
            return

        # 3. æå–å…¨æ–‡å†…å®¹
        logger.info("ğŸ“„ æå–æ–‡çŒ®å…¨æ–‡å†…å®¹...")
        extractor = TextExtractor(config_manager.get_extraction_config())
        papers_with_text = extractor.extract_batch(
            papers, max_workers=args.max_workers, text_limit=args.text_limit)

        valid_papers = [p for p in papers_with_text if p.get('full_text')]
        logger.info(f"âœ… æˆåŠŸæå– {len(valid_papers)} ç¯‡æ–‡çŒ®çš„å…¨æ–‡å†…å®¹")

        if not valid_papers:
            logger.warning("âš ï¸ æœªèƒ½æå–åˆ°ä»»ä½•æ–‡çŒ®çš„å…¨æ–‡å†…å®¹ï¼Œç¨‹åºé€€å‡º")
            return

        # 4. åŠ è½½æå–æ¨¡æ¿
        logger.info(f"ğŸ¯ åŠ è½½æå–æ¨¡æ¿: {args.template}")
        if args.custom_fields:
            template = config_manager.load_custom_template(args.custom_fields)
        else:
            template = config_manager.get_extraction_template(args.template)

        # 5. LLMåˆ†æ
        if not args.dry_run:
            logger.info("ğŸ§  å¼€å§‹å¤§æ¨¡å‹åˆ†æ...")
            analyzer = LLMAnalyzer(
                config_manager.get_llm_config(args.llm_provider))

            analyzed_papers = analyzer.analyze_batch(
                valid_papers,
                template,
                batch_size=args.batch_size,
                max_workers=args.max_workers)
        else:
            logger.info("ğŸ” è¯•è¿è¡Œæ¨¡å¼ï¼Œè·³è¿‡ LLM åˆ†æ")
            analyzed_papers = valid_papers

        # 6. æ•°æ®å¤„ç†å’Œè¾“å‡º
        logger.info("ğŸ“Š å¤„ç†æ•°æ®å¹¶ç”Ÿæˆè¾“å‡º...")
        processor = DataProcessor(config_manager.get_output_config())

        output_path = Path(args.output_dir) / args.output
        processor.generate_csv(analyzed_papers, template, output_path)

        logger.info(f"ğŸ‰ åˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_path}")

        # 7. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        stats = processor.generate_statistics(analyzed_papers)
        logger.info("ğŸ“ˆ å¤„ç†ç»Ÿè®¡:")
        logger.info(f"  - æ€»æ–‡çŒ®æ•°: {stats['total_papers']}")
        logger.info(f"  - æˆåŠŸåˆ†æ: {stats['analyzed_papers']}")
        logger.info(f"  - æå–å­—æ®µ: {stats['extracted_fields']}")
        logger.info(f"  - å¤„ç†æ—¶é—´: {stats['processing_time']:.2f}ç§’")

    except KeyboardInterrupt:
        logger.info("â›” ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"ğŸ’¥ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
        if args.verbose:
            import traceback
            logger.error(traceback.format_exc())
        sys.exit(1)


if __name__ == "__main__":
    main()
