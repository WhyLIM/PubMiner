#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PubMiner - æ¨¡å—åŒ–æ–‡çŒ®åˆ†æå·¥å…·
ä¸»ç¨‹åºå…¥å£

åŠŸèƒ½ï¼š
1. è·å– PubMed æ–‡çŒ®åŸºæœ¬ä¿¡æ¯
2. æå–å…¨æ–‡å†…å®¹ï¼ˆPMC/PDFï¼‰
3. åŸºäºå¤§æ¨¡å‹çš„ç»“æ„åŒ–ä¿¡æ¯æå–
4. ç”Ÿæˆæ ‡å‡†åŒ– CSV æŠ¥å‘Š
"""

import sys
import argparse
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from core.config_manager import ConfigManager
from core.pubmed_fetcher import PubMedFetcher
from core.text_extractor import TextExtractor
from core.llm_analyzer import LLMAnalyzer
from core.data_processor import DataProcessor
from core.query_manager import QueryManager
from utils.logger import setup_logger
from utils.rich_logger import setup_rich_logger, get_rich_logger, print_welcome, print_config_summary, print_results_summary


class PubMiner:
    """PubMiner ä¸»ç±» - æä¾›ç¼–ç¨‹æ¥å£"""

    def __init__(self, config_path=None, llm_provider='deepseek'):
        """
        åˆå§‹åŒ– PubMiner

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            llm_provider: LLM æä¾›å•†
        """
        # å¦‚æœæ²¡æœ‰æŒ‡å®šé…ç½®è·¯å¾„ï¼Œä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„é…ç½®
        if config_path is None:
            project_root = Path(__file__).parent
            config_path = project_root / 'config' / 'default_config.json'

        self.config_manager = ConfigManager(str(config_path))
        self.llm_provider = llm_provider

        # è®¾ç½® Rich æ—¥å¿—ç³»ç»Ÿ
        self.rich_logger = setup_rich_logger(level=logging.INFO,
                                             log_dir=Path('logs'),
                                             console_width=120,
                                             show_time=True,
                                             show_path=False)
        self.logger = setup_logger(logging.INFO, Path('logs'))

        # åˆå§‹åŒ–ç»„ä»¶
        # åˆå¹¶ pubmed é…ç½®å’Œ citation_details é…ç½®ä¼ é€’ç»™ PubMedFetcher
        pubmed_config = self.config_manager.get_pubmed_config()
        output_config = self.config_manager.get_output_config()
        pubmed_config.update({'citation_details': output_config.get('citation_details', {})})

        self.fetcher = PubMedFetcher(pubmed_config)
        self.extractor = TextExtractor(self.config_manager.get_extraction_config())
        self.analyzer = LLMAnalyzer(self.config_manager.get_llm_config(llm_provider))
        self.processor = DataProcessor(output_config)
        self.query_manager = QueryManager(self.config_manager)

        self.logger.info("âœ… PubMiner åˆå§‹åŒ–å®Œæˆ")

    def analyze_by_query(self,
                         query,
                         template_name='standard',
                         max_results=50,
                         include_fulltext=True,
                         max_workers=4,
                         language=None,
                         custom_template_file=None):
        """
        æ ¹æ®æŸ¥è¯¢è¯åˆ†ææ–‡çŒ®

        Args:
            query: PubMed æŸ¥è¯¢è¯
            template_name: æå–æ¨¡æ¿åç§°
            max_results: æœ€å¤§ç»“æœæ•°
            include_fulltext: æ˜¯å¦åŒ…å«å…¨æ–‡
            max_workers: å¹¶å‘æ•°
            language: è¾“å‡ºè¯­è¨€ (Chinese, English, etc.)ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
            custom_template_file: è‡ªå®šä¹‰æ¨¡æ¿æ–‡ä»¶è·¯å¾„

        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        # å¦‚æœæœªæŒ‡å®šè¯­è¨€ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤è¯­è¨€
        if language is None:
            language = self.config_manager.get_default_language()
        else:
            language = self.config_manager.normalize_language(language)

        self.logger.info(f"ğŸ” å¼€å§‹æŸ¥è¯¢åˆ†æ: {query}")
        self.logger.info(f"ğŸŒ è¾“å‡ºè¯­è¨€: {language}")

        # 1. è·å–æ–‡çŒ®åŸºæœ¬ä¿¡æ¯
        papers = self.fetcher.fetch_by_query(query, max_results=max_results)
        self.logger.info(f"ğŸ“š è·å–åˆ° {len(papers)} ç¯‡æ–‡çŒ®")

        if not papers:
            return []

        # 2. æå–å…¨æ–‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if include_fulltext:
            papers = self.extractor.extract_batch(papers, max_workers=max_workers)
            papers = [p for p in papers if p.get('full_text')]
            self.logger.info(f"ğŸ“„ æˆåŠŸæå– {len(papers)} ç¯‡æ–‡çŒ®å…¨æ–‡")

        # 3. LLM åˆ†æ
        if custom_template_file:
            # åŠ è½½è‡ªå®šä¹‰æ¨¡æ¿æ–‡ä»¶
            import json
            with open(custom_template_file, 'r', encoding='utf-8') as f:
                template = json.load(f)
        else:
            template = self.config_manager.get_extraction_template(template_name)
        analyzed_papers = self.analyzer.analyze_batch(papers, template, max_workers=max_workers, language=language)

        self.logger.info(f"âœ… åˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(analyzed_papers)} ç¯‡æ–‡çŒ®")
        return analyzed_papers

    def analyze_by_pmids(self, pmids, template_name='standard', include_fulltext=True, max_workers=4, language=None):
        """
        æ ¹æ® PMID åˆ—è¡¨åˆ†ææ–‡çŒ®

        Args:
            pmids: PMID åˆ—è¡¨
            template_name: æå–æ¨¡æ¿åç§°
            include_fulltext: æ˜¯å¦åŒ…å«å…¨æ–‡
            max_workers: å¹¶å‘æ•°
            language: è¾“å‡ºè¯­è¨€ï¼ˆNone æ—¶ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼ï¼‰

        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        # å¦‚æœæœªæŒ‡å®šè¯­è¨€ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤è¯­è¨€
        if language is None:
            language = self.config_manager.get_default_language()

        self.logger.info(f"ğŸ” å¼€å§‹ PMID åˆ†æ: {len(pmids)} ç¯‡æ–‡çŒ®")
        self.logger.info(f"ğŸŒ è¾“å‡ºè¯­è¨€: {language}")

        # 1. è·å–æ–‡çŒ®åŸºæœ¬ä¿¡æ¯
        papers = self.fetcher.fetch_by_pmid_list(pmids)
        self.logger.info(f"ğŸ“š è·å–åˆ° {len(papers)} ç¯‡æ–‡çŒ®")

        if not papers:
            return []

        # 2. æå–å…¨æ–‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if include_fulltext:
            papers = self.extractor.extract_batch(papers, max_workers=max_workers)
            papers = [p for p in papers if p.get('full_text')]
            self.logger.info(f"ğŸ“„ æˆåŠŸæå– {len(papers)} ç¯‡æ–‡çŒ®å…¨æ–‡")

        # 3. LLM åˆ†æ
        template = self.config_manager.get_extraction_template(template_name)
        analyzed_papers = self.analyzer.analyze_batch(papers, template, max_workers=max_workers, language=language)

        self.logger.info(f"âœ… åˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(analyzed_papers)} ç¯‡æ–‡çŒ®")
        return analyzed_papers

    def save_results(self, results, output_name='analysis_results'):
        """
        ä¿å­˜åˆ†æç»“æœ

        Args:
            results: åˆ†æç»“æœåˆ—è¡¨
            output_name: è¾“å‡ºæ–‡ä»¶åå‰ç¼€
        """
        from datetime import datetime
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = Path('results') / f'{output_name}_{timestamp}.csv'

        # ä½¿ç”¨æ ‡å‡†æ¨¡æ¿ï¼ˆè¿™é‡Œéœ€è¦æ”¹è¿›ä»¥æ”¯æŒåŠ¨æ€æ¨¡æ¿ï¼‰
        template = self.config_manager.get_extraction_template('standard')
        self.processor.generate_csv(results, template, output_path)

        self.logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        return output_path

    def get_available_templates(self):
        """è·å–å¯ç”¨çš„æå–æ¨¡æ¿åˆ—è¡¨"""
        templates = self.config_manager.get_extraction_templates()
        return list(templates.keys())

    def create_custom_template(self, fields, template_name, template_description="Custom template"):
        """
        åˆ›å»ºè‡ªå®šä¹‰æ¨¡æ¿

        Args:
            fields: å­—æ®µå®šä¹‰åˆ—è¡¨
            template_name: æ¨¡æ¿åç§°
            template_description: æ¨¡æ¿æè¿°
        """
        from extractors.custom_extractor import CustomExtractor
        extractor = CustomExtractor(self.config_manager.get_config())
        template = extractor.create_template_from_fields(fields, template_description)

        # è¿™é‡Œå¯ä»¥æ·»åŠ ä¿å­˜æ¨¡æ¿çš„é€»è¾‘
        return template

    def execute_batch_queries(self, config_file):
        """
        æ‰§è¡Œæ‰¹é‡æŸ¥è¯¢ä»»åŠ¡

        Args:
            config_file: æŸ¥è¯¢é…ç½®æ–‡ä»¶è·¯å¾„

        Returns:
            æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        return self.query_manager.execute_batch_queries(config_file, self)

    def create_query_config_example(self, output_file="query_config_example.json"):
        """
        åˆ›å»ºæŸ¥è¯¢é…ç½®ç¤ºä¾‹æ–‡ä»¶

        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        self.query_manager.create_example_config(output_file)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='PubMiner - æ¨¡å—åŒ–æ–‡çŒ®åˆ†æå·¥å…·',
                                     formatter_class=argparse.RawDescriptionHelpFormatter,
                                     epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æŒ‰æŸ¥è¯¢è¯åˆ†ææ–‡çŒ®
  python main.py --query "covid-19 AND vaccine" --output results.csv

  # æŒ‰ PMID åˆ—è¡¨åˆ†æ
  python main.py --pmids 12345678,87654321 --output results.csv

  # ä½¿ç”¨è‡ªå®šä¹‰æå–æ¨¡æ¿
  python main.py --query "aging biomarker" --template aging_biomarker --output aging_results.csv

  # æŒ‡å®šå¤§æ¨¡å‹é…ç½®
  python main.py --query "cancer treatment" --llm-provider deepseek --output cancer_results.csv
        """)

    # è¾“å…¥å‚æ•°
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument('--query', type=str, help='PubMed æŸ¥è¯¢è¯')
    input_group.add_argument('--pmids', type=str, help='PMID åˆ—è¡¨ï¼Œé€—å·åˆ†éš”')
    input_group.add_argument('--pmid-file', type=str, help='åŒ…å« PMID åˆ—è¡¨çš„æ–‡ä»¶è·¯å¾„')
    input_group.add_argument('--batch-config', type=str, help='æ‰¹é‡æŸ¥è¯¢é…ç½®æ–‡ä»¶è·¯å¾„')
    input_group.add_argument('--create-query-example', action='store_true', help='åˆ›å»ºæŸ¥è¯¢é…ç½®ç¤ºä¾‹æ–‡ä»¶')

    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output', type=str, help='è¾“å‡º CSV æ–‡ä»¶è·¯å¾„ï¼ˆå•ä¸ªæŸ¥è¯¢æ—¶å¿…éœ€ï¼‰')
    parser.add_argument('--output-dir', type=str, default='output', help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šoutputï¼‰')

    # å¤„ç†å‚æ•°
    parser.add_argument('--template', type=str, default='standard', help='æå–æ¨¡æ¿ï¼ˆstandard/custom ç­‰ï¼Œé»˜è®¤ï¼šstandardï¼‰')
    parser.add_argument('--custom-fields', type=str, help='è‡ªå®šä¹‰å­—æ®µ JSON æ–‡ä»¶è·¯å¾„')

    # LLM å‚æ•°
    parser.add_argument('--llm-provider',
                        type=str,
                        default='deepseek',
                        choices=['openai', 'deepseek', 'qwen', 'volcengine'],
                        help='å¤§æ¨¡å‹æä¾›å•†ï¼ˆé»˜è®¤ï¼šdeepseekï¼‰')
    parser.add_argument('--llm-model', type=str, help='å…·ä½“æ¨¡å‹åç§°ï¼ˆè¦†ç›–é»˜è®¤é…ç½®ï¼‰')
    parser.add_argument('--api-key', type=str, help='API å¯†é’¥ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')

    # ä¼˜åŒ–å‚æ•°
    parser.add_argument('--max-workers', type=int, default=4, help='æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤ï¼š4ï¼‰')
    parser.add_argument('--batch-size', type=int, default=10, help='æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤ï¼š10ï¼‰')
    parser.add_argument('--text-limit', type=int, default=15000, help='å•ç¯‡æ–‡çŒ®æ–‡æœ¬é•¿åº¦é™åˆ¶ï¼ˆé»˜è®¤ï¼š15000 å­—ç¬¦ï¼‰')

    # å…¶ä»–å‚æ•°
    parser.add_argument('--config',
                        type=str,
                        default='config/default_config.json',
                        help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šconfig/default_config.jsonï¼‰')
    parser.add_argument('--resume', action='store_true', help='æ–­ç‚¹ç»­ä¼ æ¨¡å¼')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    parser.add_argument('--dry-run', action='store_true', help='è¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸å®é™…è°ƒç”¨ APIï¼‰')

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()

    # è®¾ç½® Rich æ—¥å¿—ç³»ç»Ÿ
    log_level = logging.DEBUG if args.verbose else logging.INFO
    rich_logger = setup_rich_logger(level=log_level,
                                    log_dir=Path('logs'),
                                    console_width=120,
                                    show_time=True,
                                    show_path=args.verbose)
    logger = setup_logger(log_level, Path('logs'))

    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    print_welcome()

    try:
        # å¤„ç†åˆ›å»ºæŸ¥è¯¢é…ç½®ç¤ºä¾‹çš„æƒ…å†µ
        if args.create_query_example:
            from core.query_manager import QueryManager
            config_manager = ConfigManager(args.config)
            query_manager = QueryManager(config_manager)
            output_file = args.output if args.output else "query_config_example.json"
            query_manager.create_example_config(output_file)
            return

        # éªŒè¯è¾“å‡ºæ–‡ä»¶å‚æ•°
        if not args.batch_config and not args.output:
            logger.error("âŒ é”™è¯¯: å•ä¸ªæŸ¥è¯¢æ¨¡å¼éœ€è¦æŒ‡å®š --output å‚æ•°")
            sys.exit(1)

        # å¤„ç†æ‰¹é‡æŸ¥è¯¢é…ç½®çš„æƒ…å†µ
        if args.batch_config:
            rich_logger.print_section("æ‰¹é‡æŸ¥è¯¢æ¨¡å¼")
            rich_logger.info(f"é…ç½®æ–‡ä»¶: [path]{args.batch_config}[/path]")

            # åˆå§‹åŒ– PubMiner
            pubminer = PubMiner(args.config, args.llm_provider)

            # æ‰§è¡Œæ‰¹é‡æŸ¥è¯¢
            with rich_logger.status("æ‰§è¡Œæ‰¹é‡æŸ¥è¯¢..."):
                results = pubminer.execute_batch_queries(args.batch_config)

            rich_logger.success("æ‰¹é‡æŸ¥è¯¢æ‰§è¡Œå®Œæˆï¼")
            return

        rich_logger.print_section("æ–‡çŒ®åˆ†ææ¨¡å¼")
        rich_logger.info(f"è¾“å‡ºç›®å½•: [path]{args.output_dir}[/path]")
        rich_logger.info(f"è¾“å‡ºæ–‡ä»¶: [path]{args.output}[/path]")

        # 1. åŠ è½½é…ç½®
        rich_logger.print_section("é…ç½®åŠ è½½")
        with rich_logger.status("åŠ è½½é…ç½®æ–‡ä»¶..."):
            config_manager = ConfigManager(args.config)

        # è¦†ç›–é…ç½®å‚æ•°
        if args.api_key:
            config_manager.set_api_key(args.llm_provider, args.api_key)
            rich_logger.info("API å¯†é’¥å·²æ›´æ–°")
        if args.llm_model:
            config_manager.set_model(args.llm_provider, args.llm_model)
            rich_logger.info(f"æ¨¡å‹å·²è®¾ç½®ä¸º: [highlight]{args.llm_model}[/highlight]")

        # æ˜¾ç¤ºé…ç½®æ‘˜è¦
        config_summary = {
            "é…ç½®æ–‡ä»¶": args.config,
            "LLM æä¾›å•†": args.llm_provider,
            "æœ€å¤§å·¥ä½œçº¿ç¨‹": args.max_workers,
            "æ‰¹å¤„ç†å¤§å°": args.batch_size,
            "æ–‡æœ¬é™åˆ¶": f"{args.text_limit} å­—ç¬¦" if args.text_limit else "æ— é™åˆ¶"
        }
        print_config_summary(config_summary)

        # 2. è·å–æ–‡çŒ®åŸºæœ¬ä¿¡æ¯
        rich_logger.print_section("æ–‡çŒ®è·å–")
        fetcher = PubMedFetcher(config_manager.get_pubmed_config())

        with rich_logger.progress("è·å–æ–‡çŒ®ä¿¡æ¯...") as (progress, task):
            if args.query:
                rich_logger.info(f"æŸ¥è¯¢è¯­å¥: [highlight]{args.query}[/highlight]")
                papers = fetcher.fetch_by_query(args.query, resume=args.resume)
            elif args.pmids:
                pmid_list = [pmid.strip() for pmid in args.pmids.split(',')]
                rich_logger.info(f"PMID åˆ—è¡¨: [number]{len(pmid_list)}[/number] ä¸ª")
                papers = fetcher.fetch_by_pmid_list(pmid_list, resume=args.resume)
            elif args.pmid_file:
                with open(args.pmid_file, 'r', encoding='utf-8') as f:
                    pmid_list = [line.strip() for line in f if line.strip()]
                rich_logger.info(f"PMID æ–‡ä»¶: [path]{args.pmid_file}[/path] ([number]{len(pmid_list)}[/number] ä¸ª)")
                papers = fetcher.fetch_by_pmid_list(pmid_list, resume=args.resume)

        rich_logger.success(f"è·å–åˆ° [number]{len(papers)}[/number] ç¯‡æ–‡çŒ®çš„åŸºæœ¬ä¿¡æ¯")

        if not papers:
            rich_logger.warning("æœªè·å–åˆ°ä»»ä½•æ–‡çŒ®ï¼Œç¨‹åºé€€å‡º")
            return

        # 3. æå–å…¨æ–‡å†…å®¹
        rich_logger.print_section("å…¨æ–‡æå–")
        extractor = TextExtractor(config_manager.get_extraction_config())

        with rich_logger.progress("æå–å…¨æ–‡å†…å®¹...") as (progress, task):
            papers_with_text = extractor.extract_batch(papers, max_workers=args.max_workers, text_limit=args.text_limit)

        valid_papers = [p for p in papers_with_text if p.get('full_text')]
        rich_logger.success(f"æˆåŠŸæå– [number]{len(valid_papers)}[/number] ç¯‡æ–‡çŒ®çš„å…¨æ–‡å†…å®¹")

        if not valid_papers:
            rich_logger.warning("æœªèƒ½æå–åˆ°ä»»ä½•æ–‡çŒ®çš„å…¨æ–‡å†…å®¹ï¼Œç¨‹åºé€€å‡º")
            return

        # 4. åŠ è½½æå–æ¨¡æ¿
        rich_logger.print_section("æ¨¡æ¿é…ç½®")
        rich_logger.info(f"æå–æ¨¡æ¿: [highlight]{args.template}[/highlight]")

        if args.custom_fields:
            template = config_manager.load_custom_template(args.custom_fields)
            rich_logger.info(f"è‡ªå®šä¹‰å­—æ®µ: [number]{len(args.custom_fields)}[/number] ä¸ª")
        else:
            template = config_manager.get_extraction_template(args.template)

        # 5. LLM åˆ†æ
        rich_logger.print_section("AI åˆ†æ")
        if not args.dry_run:
            rich_logger.info(f"LLM æä¾›å•†: [highlight]{args.llm_provider}[/highlight]")
            analyzer = LLMAnalyzer(config_manager.get_llm_config(args.llm_provider))

            with rich_logger.progress("æ‰§è¡Œ AI åˆ†æ...") as (progress, task):
                analyzed_papers = analyzer.analyze_batch(valid_papers,
                                                         template,
                                                         batch_size=args.batch_size,
                                                         max_workers=args.max_workers)
        else:
            rich_logger.warning("è¯•è¿è¡Œæ¨¡å¼ï¼Œè·³è¿‡ LLM åˆ†æ")
            analyzed_papers = valid_papers

        # 6. æ•°æ®å¤„ç†å’Œè¾“å‡º
        rich_logger.print_section("ç»“æœè¾“å‡º")
        processor = DataProcessor(config_manager.get_output_config())

        output_path = Path(args.output_dir) / args.output
        with rich_logger.status("ç”Ÿæˆ CSV æ–‡ä»¶..."):
            processor.generate_csv(analyzed_papers, template, output_path)

        rich_logger.success(f"åˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: [path]{output_path}[/path]")

        # 7. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        stats = processor.generate_statistics(analyzed_papers)
        logger.info("ğŸ“ˆ å¤„ç†ç»Ÿè®¡:")
        logger.info(f"- æ€»æ–‡çŒ®æ•°: {stats['total_papers']}")
        logger.info(f"- æˆåŠŸåˆ†æ: {stats['analyzed_papers']}")
        logger.info(f"- æå–å­—æ®µ: {stats['extracted_fields']}")
        logger.info(f"- å¤„ç†æ—¶é—´: {stats['processing_time']:.2f} ç§’")

    except KeyboardInterrupt:
        logger.info("â›” ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"ğŸ’¥ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
        if args.verbose:
            import traceback
            logger.error(traceback.format_exc())
        sys.exit(1)


if __name__ == "__main__":
    main()
